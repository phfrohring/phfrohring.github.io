<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1"/>
        <title>Pierre-Henry Fröhring</title>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css" type="text/css"/>
        <link rel="stylesheet" type="text/css" href="/css/style.css"/>
                <link rel="icon" type="image/png" href="/images/favicon.png"/>
                <style type="text/css">
            div.sourceCode { overflow-x: auto; }
            table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
              margin: 0; padding: 0; vertical-align: baseline; border: none; }
            table.sourceCode { width: 100%; line-height: 100%; }
            td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
            td.sourceCode { padding-left: 5px; }
            code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
            code > span.dt { color: #902000; } /* DataType */
            code > span.dv { color: #40a070; } /* DecVal */
            code > span.bn { color: #40a070; } /* BaseN */
            code > span.fl { color: #40a070; } /* Float */
            code > span.ch { color: #4070a0; } /* Char */
            code > span.st { color: #4070a0; } /* String */
            code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
            code > span.ot { color: #007020; } /* Other */
            code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
            code > span.fu { color: #06287e; } /* Function */
            code > span.er { color: #ff0000; font-weight: bold; } /* Error */
            code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
            code > span.cn { color: #880000; } /* Constant */
            code > span.sc { color: #4070a0; } /* SpecialChar */
            code > span.vs { color: #4070a0; } /* VerbatimString */
            code > span.ss { color: #bb6688; } /* SpecialString */
            code > span.im { } /* Import */
            code > span.va { color: #19177c; } /* Variable */
            code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
            code > span.op { color: #666666; } /* Operator */
            code > span.bu { } /* BuiltIn */
            code > span.ex { } /* Extension */
            code > span.pp { color: #bc7a00; } /* Preprocessor */
            code > span.at { color: #7d9029; } /* Attribute */
            code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
            code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
            code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
            code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
        </style>
                        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" /><script type="text/javascript">window.onload = function(){var mathElements = document.getElementsByClassName("math");
        for (var i=0; i < mathElements.length; i++)
        {
         var texText = mathElements[i].firstChild
         katex.render(texText.data, mathElements[i])
        }}
        </script>
            </head>

    <body>
        <div class="top-wrapper">
            <header class="top-header" title="Found at: https://hayo.io/under_development/wp-content/uploads/2017/01/thumbnail2-1080x675.jpg" style="background-image: url(/images/header-orig-computer-vision-0881.jpg);background-size: cover; background-position: center;"></header>

            <div class="columns_1">
                <nav class="navigation">
                    <ul class="list_of-predifined_publications">
                        <li class="predefined_publication"><a href="/pubs/curriculum-vitae-c5566488.html">CV</a></li>
                        <li class="predefined_publication"><a href="/">Search</a></li>
                    </ul>
                    <input class="card search_box" type="text" id="search_box" placeholder="some words   tag:some_tag">
                </nav>

                <div class="content">
                    <div class="publication-wrapper">
                                                <header>
                            <h1 class="title">Computer Vision</h1>
                                                                                                                <p class="date">2017-07-27</p>
                                                                                                                      <p class="author"><a href="mailto:contact@pierrehenryfrohring.com">Pierre-Henry Fröhring</a></p>
                                                                                  </header>
                                                                        <nav id="TOC">
                            <ul>
                            <li><a href="#image-distortion">Image Distortion</a></li>
                            <li><a href="#camera-calibration">Camera Calibration</a></li>
                            <li><a href="#perspective-transform">Perspective Transform</a></li>
                            <li><a href="#edge-detection">Edge Detection</a></li>
                            </ul>
                        </nav>
                                                <h1 id="image-distortion">Image Distortion</h1>
<ul>
<li>Problem: hard to take correct actions in the presence of distortions.
<ul>
<li>World ≈ 3D euclidian space.</li>
<li>World → Sensors → 2D image.</li>
<li>Distortion ≡ difference between mathematical 2D projection of the world and projection built through sensors.</li>
<li>Distortion ⇒ errors when trying to rebuild 3D scene from 2D projections of that scene ⇒ erroneous actions</li>
<li>So: we need to get rid of distortions.</li>
</ul></li>
<li>Radial distortions ≡ borders of the lense curve rays of light more than in the center.</li>
<li>Tangential distortions ≡ lens not perfectly parallel with the sensor.</li>
<li>Distortion Coefficients ≡ [k1, k2, p1, p2, k3], 5 numbers that measure the radial and tengential distortions.</li>
<li>Image ≡ I, Corrected Image ≡ CI</li>
<li>point in I ≡ (x,y), corrected point in CI ≡ (x’,y’), center of corrected image (x_c,y_c).</li>
<li>r ≡ ‖(x’,y’) (x_c,y_c)‖</li>
<li>Radial Distortion Correction ≡ <span class="math display">\displaystyle  [x&#39;,y&#39;] = [x(1+k_1r^2+k_2r^3+k_3r^6),y(1+k_1r^2+k_2r^3+k_3r^6)] </span></li>
<li>Tangential Distortion Correction ≡ <span class="math display">\displaystyle  [x&#39;,y&#39;] = [x+2p_1xy+p_2(r^2+2x^2),y+p_1(r^2+2y^2)+(2p_2xy)] </span></li>
<li>Compare a known image and a distorted image to deduce Distortion Coefficients.</li>
</ul>
<h1 id="camera-calibration">Camera Calibration</h1>
<ul>
<li>Camera Calibration ≡ Compute Distortion Coefficients.</li>
<li>Calibrate on about 20 images.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">ny <span class="op">=</span> <span class="dv">7</span> <span class="co"># Number of interior lines.</span>
nx <span class="op">=</span> <span class="dv">6</span> <span class="co"># Number of interior points per interior line.</span>


<span class="co"># objpoints ≡ [(1,2,0), …] ≡ 3D coordinates of the corners relative to an arbitrary reference</span>
<span class="co"># point on the chessboard. &quot;1&quot; represents the length of a side of a square.</span>
objpoints <span class="op">=</span> np.zeros((nx<span class="op">*</span>ny,<span class="dv">3</span>), np.float32)
objpoints[:,:<span class="dv">2</span>] <span class="op">=</span> np.mgrid[<span class="dv">0</span>:ny,<span class="dv">0</span>:nx].T.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">2</span>)


img <span class="op">=</span> cv2.imread(fname)
gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)


ret, corners <span class="op">=</span> cv2.findChessboardCorners(gray, (nx, ny), <span class="va">None</span>)
<span class="co"># ret ≡ True if pattern is found else False</span>
<span class="co"># corners ≡ [(1,2), …] ≡ 2D coordinates of the corners on the image of the chessboard.</span>


cv2.drawChessboardCorners(img, (nx, ny), corners, ret)
plt.imshow(img)
<span class="co"># Image with found corners found drawn on the image ≈ litmus test.</span>


criteria <span class="op">=</span> (cv2.TERM_CRITERIA_EPS <span class="op">+</span> cv2.TERM_CRITERIA_MAX_ITER, <span class="dv">30</span>, <span class="fl">0.001</span>)
corrected_corners <span class="op">=</span> cv2.cornerSubPix(gray,corners,(<span class="dv">11</span>,<span class="dv">11</span>),(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>),criteria)
ret, mtx, dist, rvecs, tvecs <span class="op">=</span> cv2.calibrateCamera(objpoints, corrected_corners, gray.shape[::<span class="op">-</span><span class="dv">1</span>], <span class="va">None</span>, <span class="va">None</span>)
<span class="co"># mtx ≡ Camera Matrix ≡ focal length, optical center, specific to the camera and constant.</span>
<span class="co"># dist ≡ Distortion Coefficients</span>
<span class="co"># rvecs ≡ Rotation vectors</span>
<span class="co"># tvecs ≡ Translation vectors</span>

dst <span class="op">=</span> cv2.undistort(img, mtx, dist, <span class="va">None</span>, mtx)
<span class="co"># dst ≡ undistorted image</span></code></pre></div>
<h1 id="perspective-transform">Perspective Transform</h1>
<ul>
<li>Image projections of a 3D scene into a 2D plane make distances wrong: ‖(x,y,z)‖ ≠ ‖(x,y)‖ for a projection along the z axis.</li>
<li>Wrong distances is a problem when trying to take actions to move around without bumping into things.</li>
<li>It is then necessary to apply some kind of transforms to a 2D image of a 3D scene in order to preserve some kind of distances: taking actions based on the 2D image should map to expected results in the 3D scene up to the transformation choosen (assuming everything else being correct).</li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">undist <span class="op">=</span> cv2.undistort(img, mtx, dist, <span class="va">None</span>, mtx)
gray <span class="op">=</span> cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)
ret, corners <span class="op">=</span> cv2.findChessboardCorners(gray, (nx, ny), <span class="va">None</span>)

<span class="cf">if</span> ret <span class="op">==</span> <span class="va">True</span>:
    cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)

    <span class="co"># src ≡ four points defining a rectangle on the image to be transformed.</span>
    <span class="co"># dst ≡ four points defining a rectangle where we would like them to appear on the transformed image.</span>
    src <span class="op">=</span> np.float32([corners[<span class="dv">0</span>], corners[nx<span class="op">-</span><span class="dv">1</span>], corners[<span class="op">-</span><span class="dv">1</span>], corners[<span class="op">-</span>nx]])
    img_size <span class="op">=</span> (gray.shape[<span class="dv">1</span>], gray.shape[<span class="dv">0</span>])
    offset <span class="op">=</span> <span class="dv">100</span>
    dst <span class="op">=</span> np.float32([
        [offset, offset],
        [img_size[<span class="dv">0</span>]<span class="op">-</span>offset, offset],
        [img_size[<span class="dv">0</span>]<span class="op">-</span>offset, img_size[<span class="dv">1</span>]<span class="op">-</span>offset],
        [offset, img_size[<span class="dv">1</span>]<span class="op">-</span>offset]]
    )
    M <span class="op">=</span> cv2.getPerspectiveTransform(src, dst)
    <span class="co"># M ≡ Transform Matrix</span>

    warped <span class="op">=</span> cv2.warpPerspective(undist, M, img_size)</code></pre></div>
<h1 id="edge-detection">Edge Detection</h1>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">img <span class="op">=</span> cv2.imread(file_name)
gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
sobelx <span class="op">=</span> cv2.Sobel(gray, cv2.CV_64F, <span class="dv">1</span>, <span class="dv">0</span>,ksize<span class="op">=</span><span class="dv">5</span>) <span class="co"># x direction, Sobel kernel size should be an odd number.</span>
sobely <span class="op">=</span> cv2.Sobel(gray, cv2.CV_64F, <span class="dv">0</span>, <span class="dv">1</span>,ksize<span class="op">=</span><span class="dv">5</span>) <span class="co"># y direction</span>
abs_sobel <span class="op">=</span> np.sqrt(sobelx<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> sobely<span class="op">**</span><span class="dv">2</span>)
scaled_sobel <span class="op">=</span> np.uint8(<span class="dv">255</span><span class="op">*</span>abs_sobel<span class="op">/</span>np.<span class="bu">max</span>(abs_sobel))
binary <span class="op">=</span> np.zeros_like(scaled_sobel)
thresh_min <span class="op">=</span> <span class="dv">20</span>
thresh_max <span class="op">=</span> <span class="dv">100</span>
binary[(thresh_min <span class="op">&lt;=</span> scaled_sobel) <span class="op">&amp;</span> (scaled_sobel <span class="op">&lt;=</span> thresh_max)] <span class="op">=</span> <span class="dv">1</span>
plt.imshow(binary, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</code></pre></div>
                                            </div>
                </div>
            </div>
        </div>
    </body>
</html>
